{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Detection with SMOTEENN sampling\n",
    "\n",
    "Anomaly Detection is one of popular machine learning topics and use cases. A unique challenge to this scenario is classifying fraud with tiny sample size of actual fraud. Most datasets have an imbalance number of fraudulent/legit transactions, training a model without any sampling methods applied will yield dangerous results (the model is biased towards one class given its biased training data).\n",
    "\n",
    "In this example, we demonstrate fraud detection using random forest classifier with SMOTEENN to resample our data.\n",
    "\n",
    "### Table of Content\n",
    "- [Data import and pre-process](#Import-Data-and-Pre-Process)\n",
    "- Classifying without over-sampling\n",
    "- Classifying after over-sampling\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Pre-Process\n",
    "\n",
    "We're using credit card data from [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud). Fraud transactions are marked as `1` in `Class` column. As you can see, there's less than 1% of fraud transactions in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"data/creditcard.csv\")\n",
    "raw_data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into training and test sets with 70:30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 199364 rows\n",
      "test data: 85443 rows\n"
     ]
    }
   ],
   "source": [
    "def feature_label_split(data, label_name):\n",
    "    \"\"\"Split dataset to features and labels.\"\"\"\n",
    "    \n",
    "    labels = np.array(data[label_name])\n",
    "    features = np.array(data.drop(label_name, axis=1))\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "features, labels = feature_label_split(raw_data, label_name=\"Class\")\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "print(\"training data: {} rows\".format(train_x.shape[0]))\n",
    "print(\"test data: {} rows\".format(test_x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train_x, test_x, train_y):\n",
    "    \"\"\"Execute random forest classifier.\"\"\"\n",
    "    \n",
    "    forest = RandomForestClassifier(n_estimators=500, random_state=69)\n",
    "    \n",
    "    forest.fit(train_x, train_y)\n",
    "    predictions = forest.predict(test_x)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "    \n",
    "def report(y_true, y_predict):\n",
    "    \"\"\"Show model performance report.\"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_predict)\n",
    "    print(\"[CONFUSION MATRIX]\")\n",
    "    print(\"True Positive: {}\\tFalse Positive: {}\".format(cm[0][0], cm[0][1]))\n",
    "    print(\"False Negative: {}\\tTrue Negative: {}\".format(cm[1][0], cm[1][1]))\n",
    "\n",
    "    # recall/precision.\n",
    "    print(\"\\n[PRECISION/RECALL]\")\n",
    "    print(classification_report(y_true, y_predict))\n",
    "    \n",
    "    print(\"\\nEND REPORT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying without oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFUSION MATRIX]\n",
      "True Positive: 85286\tFalse Positive: 8\n",
      "False Negative: 30\tTrue Negative: 119\n",
      "\n",
      "[PRECISION/RECALL]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85294\n",
      "           1       0.94      0.80      0.86       149\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.90      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "END REPORT\n",
      "Wall time: 11min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = random_forest(train_x, test_x, train_y)\n",
    "\n",
    "report(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, our performed really well on legit transactions (Class `0`) since it represents 99% of the dataset. It didn't do so well on predicting fraud transactions due to high number of false negatives (Type II Error) in our confusion matrix. Same results is shown on our precision/recall report (80% recall).\n",
    "\n",
    "This isn't a good model because *it predicted many transactions as legit, but were actually frauds*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversampling using SMOTE\n",
    "\n",
    "Assuming `x` is our features, and `y` is our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = fraud_data.drop(\"Class\", axis=1).copy()\n",
    "y = fraud_data[\"Class\"].copy()\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "sx, sy = smote.fit_sample(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:  (398041, 30) (398041,)\n",
      "Test Dataset:  (170589, 30) (170589,)\n"
     ]
    }
   ],
   "source": [
    "s_train_features, s_test_features, s_train_labels, s_test_labels = train_test_split(sx, sy, test_size=0.3)\n",
    "\n",
    "print(\"Train Dataset: \", s_train_features.shape, s_train_labels.shape)\n",
    "print(\"Test Dataset: \", s_test_features.shape, s_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrain random forest model with dataset using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create the model.\n",
    "smote_forest = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "\n",
    "# train the model.\n",
    "smote_forest.fit(s_train_features, s_train_labels)\n",
    "\n",
    "# make predictions.\n",
    "s_predictions = smote_forest.predict(s_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smote_test_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4c9037ae5e36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmote_test_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmote_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'smote_test_features' is not defined"
     ]
    }
   ],
   "source": [
    "report(smote_test_features, smote_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
